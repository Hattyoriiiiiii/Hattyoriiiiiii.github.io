---
layout: post
author: hattyoriiiiiii
title: K-meansクラスタリング
date: 2022-10-17
description: K-meansクラスタリングの流れ
tags: DataScience
categories: 機械学習 Colaboratory
---

<br>

### 概要

- クラスタリングとは、データをいくつかのグループに分ける教師なし学習
- K-Meansはその中の1つで、クラスタ中心からの距離をもとにクラスターの分類を行う

<br>

### 流れ

<br>

<ol>
    <li>データセットの読み込み</li>
    <li>データの標準化</li>
    <li>クラスターの数を決定する</li>
    <li>クラスタリング</li>
</ol>

<br>

### Google Colabでk-meansクラスタリング

必要なモジュール・パッケージをインポートします。

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn import preprocessing
from sklearn.cluster import KMeans
```

<br>

まずは、データの読み込みと表示を行い、どのようなデータなのかを確認します。
`pandas`の`DataFrame`というデータ構造で保持します。

```python
df = pd.read_csv("/content/sample_data/california_housing_train.csv")
df.head()
```

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/blog/2022/2022-10-26-df_head.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    データの読み込みと表示
</div>

<br>

簡単にデータの分布を見てみます。`seaborn`など可視化用のライブラリを用いた方が綺麗に表示できます。

```python
df.hist(bins = 50, figsize=(20, 15))
plt.show()
```

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/blog/2022/2022-10-26-hist.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    まずは、どういう分布のデータなのかを見る
</div>

<br>

次にデータの標準化を行い、各特徴量のスケールを合わせます。

```python
X = df.copy()
sc = preprocessing.StandardScaler()
sc.fit(X)
X_norm = sc.transform(X)
```

<br>

クラスタリングをするための準備ができました。
k-meansクラスタリングは、いくつのクラスターに分類するかを前もって決めないといけない教師なし学習です。どれくらいのクラスター数が適当なのかをelbow法を用いて決めます。

```python
start, end = 1, 30
dist_list = []
for i in range(start, end):
    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=7)
    kmeans.fit(X_norm)
    dist_list.append(kmeans.inertia_)

plt.plot(range(start, end), dist_list, marker='+')
plt.title('elbow method')
plt.xlabel('Number of clusters')
plt.ylabel('Distortion')
plt.show()
```

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/blog/2022/2022-10-26-elbow.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    カクッと曲がり始めたところを目安にクラスター数を決める
</div>

<br>

次に、elbow法で決めたクラスター数をもとにクラスタリングを行います。

```python
# kmeansモデルの作成
kmeans = KMeans(n_clusters=5, init='k-means++', random_state=7)
# クラスターの重心
result = kmeans.fit(X_norm)
```

<br>

得られた結果は元のデータフレームと結合させます。

```python
# クラスター番号の予測
y_pred = kmeans.predict(X_norm)

# クラスター番号をpandasのSeriesで保持
labels = pd.Series(kmeans.labels_, name='cluster')
print(labels.value_counts(sort=False))

# 元データにクラスター番号の結合
df_merge = pd.concat([df, labels], axis=1)
```

<br>

`cluster`という列が追加されているか確認を行います。

```python
df_merge.head()
```

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/blog/2022/2022-10-26-df_merge_head.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    一番右に追加されている
</div>


<br>

最後に、各クラスターはどういう特徴を持っているのかを確認します。

```python
fig, axes = plt.subplots(3, 3, figsize=(20, 15))

cols = df_merge.columns
axes = axes.ravel()


for col, ax in zip(cols, axes):
    ax.set_title(col)
    sns.violinplot(data = df_merge, x = "cluster", y = col, palette = "pastel", ax= ax)

plt.show()
```

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/blog/2022/2022-10-26-violin_standarized.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

<br>
<br>

#### もし、標準化を行わなかった場合

座標空間上でデータ間の距離を用いているため、1つの特徴量のデータだけ絶対値が大きいとクラスタリングの結果に影響を与えてしまいます。


<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/blog/2022/2022-10-26-violin_raw.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    標準化を行わなかった場合
</div>

<br>

今回の場合、絶対値が最も大きかった`median_house_value`という特徴量によってクラスターの分類がされていることが、上図からわかります。

`median_income`は絶対値が小さいのに影響しているように見えます。しかし、高価な家に住んでいる人の収入は高いことが予想されるため、`median_income`は`median_house_value`の影響だと考えられます。


<br>
